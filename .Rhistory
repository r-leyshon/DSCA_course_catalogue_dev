(!grepl("E learning", user_generated_li) |
!grepl("Self learning", user_generated_li) |
!grepl("Face to face", user_generated_li))
!grepl("E learning", user_generated_li) |
!grepl("Self learning", user_generated_li)
!grepl("E learning", user_generated_li)
grepl("E learning", user_generated_li)
grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li
grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li)
!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
extract_lo_detail <- function(pages){
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("\n", lowered_list_text)[length(grep("\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
#if any of these patterns are detected, assign the value to course type
# if (grepl("E learning", course_type_test) |
#     grepl("Self learning", course_type_test) |
#     grepl("Face to face", course_type_test)
# ){
lo_detail <- lo_detail_test
# } else {
#   #otherwise use placeholder text
#   course_type <- "No course type found"
#
# }
return(lo_detail)
} #end of function
#apply the function to extract course descriptions from the parsed course list
lo_detail_list <- lapply(parsed_course_pages, FUN = extract_lo_detail)
lo_detail_list
#rbind the list elements
lo_detail <- list.rbind(lo_detail_list)
lo_detail
#save as a column in dataframe
output_dataframe$learning_objectives <- lo_detail
View(output_dataframe)
pages <- parsed_course_pages[[1]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("\n", lowered_list_text)[length(grep("\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
pages <- parsed_course_pages[[2]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("\n", lowered_list_text)[length(grep("\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
list_text
start_index
pages <- parsed_course_pages[[1]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("\n", lowered_list_text)[length(grep("\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
list_text
pages <- parsed_course_pages[[2]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("\n", lowered_list_text)[length(grep("\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
list_text
extract_lo_detail <- function(pages){
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail <- lo_detail_test
return(lo_detail)
} #end of function
#apply the function to extract course descriptions from the parsed course list
lo_detail_list <- lapply(parsed_course_pages, FUN = extract_lo_detail)
pages <- parsed_course_pages[[2]]
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
lowered_list_text
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
start_index
pages <- parsed_course_pages[[1]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
start_index
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
end_index
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[2]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[3]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
start_index
end_index
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[4]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[5]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[6]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[7]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[8]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
start_index
end_index
lowered_list_text
pages <- parsed_course_pages[[1]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
list_text
extract_lo_detail <- function(pages){
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail <- lo_detail_test
return(lo_detail)
} #end of function
#apply the function to extract course descriptions from the parsed course list
lo_detail_list <- lapply(parsed_course_pages, FUN = extract_lo_detail)
lo_detail_list
pages <- parsed_course_pages[[1]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
grep("github, inc.", lowered_list_text)
grep("github, inc.", lowered_list_text)[1]
grep("github, inc.", lowered_list_text)[1] - 1
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
start_index
#find end index
end_index <- grep("github, inc.", lowered_list_text)[1] - 1
end_index
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li) |
grepl("%\n"))], collapse = "; ")
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li) |
grepl("%\n", user_generated_li))], collapse = "; ")
lo_detail_test
extract_lo_detail <- function(pages){
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
#find end index
end_index <- grep("github, inc.", lowered_list_text)[1] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li) |
grepl("%\n", user_generated_li))], collapse = "; ")
#some readme lists have \n linebreaks while others don't. Cleanse if present.
lo_detail_test <- str_replace_all(lo_detail_test, "\n", " ")
lo_detail <- lo_detail_test
return(lo_detail)
} #end of function
#apply the function to extract course descriptions from the parsed course list
lo_detail_list <- lapply(parsed_course_pages, FUN = extract_lo_detail)
lo_detail_list
pages <- parsed_course_pages[[12]]
list_text <- pages %>% html_nodes("li") %>% html_text()
list_text
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
start_index
lowered_list_text
#find end index
end_index <- grep("github, inc.", lowered_list_text)[1] - 1
end_index
extract_lo_detail <- function(pages){
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
#find end index
end_index <- grep("github, inc.", lowered_list_text)[1] - 1
#in the case of missing readmes, the above method of finding indexes can result in an end_index smaller
#than start_index. Check for this condition and assign a placeholder
if (start_index <= end_index){
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
} else {
lo_detail <- "No readme found"
return(lo_detail)
next
}
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li) |
grepl("%\n", user_generated_li))], collapse = "; ")
#some readme lists have \n linebreaks while others don't. Cleanse if present.
lo_detail_test <- str_replace_all(lo_detail_test, "\n", " ")
lo_detail <- lo_detail_test
return(lo_detail)
} #end of function
#apply the function to extract course descriptions from the parsed course list
lo_detail_list <- lapply(parsed_course_pages, FUN = extract_lo_detail)
lo_detail_list
#rbind the list elements
lo_detail <- list.rbind(lo_detail_list)
#save as a column in dataframe
output_dataframe$learning_objectives <- lo_detail
remove(list = 'lo_detail',
'lo_detail_list',
'lo_detail_test',
'extract_lo_detail')
clear()
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
extract_lo_detail <- function(pages){
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
#find end index
end_index <- grep("github, inc.", lowered_list_text)[1] - 1
#in the case of missing readmes, the above method of finding indexes can result in an end_index smaller
#than start_index. Check for this condition and assign a placeholder
if (start_index <= end_index){
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
} else {
lo_detail <- "No readme found"
return(lo_detail)
next
}
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li) |
grepl("%\n", user_generated_li))], collapse = "; ")
#some readme lists have \n linebreaks while others don't. Cleanse if present.
lo_detail_test <- str_replace_all(lo_detail_test, "\n", " ")
lo_detail <- lo_detail_test
return(lo_detail)
} #end of function
#apply the function to extract course descriptions from the parsed course list
lo_detail_list <- lapply(parsed_course_pages, FUN = extract_lo_detail)
#rbind the list elements
lo_detail <- list.rbind(lo_detail_list)
#save as a column in dataframe
output_dataframe$learning_objectives <- lo_detail
View(output_dataframe)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
version_number <- 2.0
paste("Automated email sent from dsca_course_catalogue_dev version", version_number, "Please find attached
the latest version of DSCA course catalogue. Version", version_number+0.1, "to include informative Email
content based on the reason for updating the website.")
email_text <- paste("Automated email sent from dsca_course_catalogue_dev version", version_number, "Please find attached the latest version of DSCA course catalogue. Version", version_number+0.1, "to include informative Email content based on the reason for updating the website.")
email_text
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
