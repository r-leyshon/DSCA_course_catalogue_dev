#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[3]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
start_index
end_index
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[4]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[5]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[6]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[7]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail_test
pages <- parsed_course_pages[[8]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
start_index
end_index
lowered_list_text
pages <- parsed_course_pages[[1]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("%\n", lowered_list_text)[length(grep("%\n", lowered_list_text))] + 1
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
list_text
extract_lo_detail <- function(pages){
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li))], collapse = "; ")
lo_detail <- lo_detail_test
return(lo_detail)
} #end of function
#apply the function to extract course descriptions from the parsed course list
lo_detail_list <- lapply(parsed_course_pages, FUN = extract_lo_detail)
lo_detail_list
pages <- parsed_course_pages[[1]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
#find end index
end_index <- grep("github, inc.", lowered_list_text)[length(grep("github, inc.", lowered_list_text))] - 1
grep("github, inc.", lowered_list_text)
grep("github, inc.", lowered_list_text)[1]
grep("github, inc.", lowered_list_text)[1] - 1
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
start_index
#find end index
end_index <- grep("github, inc.", lowered_list_text)[1] - 1
end_index
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
user_generated_li
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li) |
grepl("%\n"))], collapse = "; ")
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li) |
grepl("%\n", user_generated_li))], collapse = "; ")
lo_detail_test
extract_lo_detail <- function(pages){
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
#find end index
end_index <- grep("github, inc.", lowered_list_text)[1] - 1
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li) |
grepl("%\n", user_generated_li))], collapse = "; ")
#some readme lists have \n linebreaks while others don't. Cleanse if present.
lo_detail_test <- str_replace_all(lo_detail_test, "\n", " ")
lo_detail <- lo_detail_test
return(lo_detail)
} #end of function
#apply the function to extract course descriptions from the parsed course list
lo_detail_list <- lapply(parsed_course_pages, FUN = extract_lo_detail)
lo_detail_list
pages <- parsed_course_pages[[12]]
list_text <- pages %>% html_nodes("li") %>% html_text()
list_text
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
start_index
lowered_list_text
#find end index
end_index <- grep("github, inc.", lowered_list_text)[1] - 1
end_index
extract_lo_detail <- function(pages){
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
#find end index
end_index <- grep("github, inc.", lowered_list_text)[1] - 1
#in the case of missing readmes, the above method of finding indexes can result in an end_index smaller
#than start_index. Check for this condition and assign a placeholder
if (start_index <= end_index){
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
} else {
lo_detail <- "No readme found"
return(lo_detail)
next
}
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li) |
grepl("%\n", user_generated_li))], collapse = "; ")
#some readme lists have \n linebreaks while others don't. Cleanse if present.
lo_detail_test <- str_replace_all(lo_detail_test, "\n", " ")
lo_detail <- lo_detail_test
return(lo_detail)
} #end of function
#apply the function to extract course descriptions from the parsed course list
lo_detail_list <- lapply(parsed_course_pages, FUN = extract_lo_detail)
lo_detail_list
#rbind the list elements
lo_detail <- list.rbind(lo_detail_list)
#save as a column in dataframe
output_dataframe$learning_objectives <- lo_detail
remove(list = 'lo_detail',
'lo_detail_list',
'lo_detail_test',
'extract_lo_detail')
clear()
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
extract_lo_detail <- function(pages){
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
#find end index
end_index <- grep("github, inc.", lowered_list_text)[1] - 1
#in the case of missing readmes, the above method of finding indexes can result in an end_index smaller
#than start_index. Check for this condition and assign a placeholder
if (start_index <= end_index){
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
} else {
lo_detail <- "No readme found"
return(lo_detail)
next
}
#pull any list object that does not match a course type
lo_detail_test <- paste(user_generated_li[!(grepl("E learning", user_generated_li) |
grepl("Self learning", user_generated_li) |
grepl("Face to face", user_generated_li) |
grepl("%\n", user_generated_li))], collapse = "; ")
#some readme lists have \n linebreaks while others don't. Cleanse if present.
lo_detail_test <- str_replace_all(lo_detail_test, "\n", " ")
lo_detail <- lo_detail_test
return(lo_detail)
} #end of function
#apply the function to extract course descriptions from the parsed course list
lo_detail_list <- lapply(parsed_course_pages, FUN = extract_lo_detail)
#rbind the list elements
lo_detail <- list.rbind(lo_detail_list)
#save as a column in dataframe
output_dataframe$learning_objectives <- lo_detail
View(output_dataframe)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
version_number <- 2.0
paste("Automated email sent from dsca_course_catalogue_dev version", version_number, "Please find attached
the latest version of DSCA course catalogue. Version", version_number+0.1, "to include informative Email
content based on the reason for updating the website.")
email_text <- paste("Automated email sent from dsca_course_catalogue_dev version", version_number, "Please find attached the latest version of DSCA course catalogue. Version", version_number+0.1, "to include informative Email content based on the reason for updating the website.")
email_text
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
View(output_dataframe)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
View(output_dataframe)
print(output_dataframe$site_link)[11]
print(output_dataframe$site_link[11])
print(output_dataframe$site_link[12])
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
View(output_dataframe)
View(cbind.fill)
#apply the function to extract course descriptions from the parsed course list
lo_detail_list <- lapply(parsed_course_pages, FUN = extract_lo_detail)
extract_lo_detail(parsed_course_pages[1])
extract_lo_detail(parsed_course_pages[[1]])
extract_lo_detail(parsed_course_pages[[2]])
extract_lo_detail(parsed_course_pages[[3]])
pages <- parsed_course_pages[[3]]
list_text <- pages %>% html_nodes("li") %>% html_text()
list_text
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
lowered_list_text
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("fetching contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
start_index
lowered_list_text
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("contributors", lowered_list_text)[length(grep("fetching contributors", lowered_list_text))] + 2
start_index
#subset this character vector by:
#start  - the last text value that contains "\n" plus one
#end - the first value that contains 'Github, Inc.' minus one
#find first index
start_index <- grep("contributors", lowered_list_text)[length(grep("contributors", lowered_list_text))] + 2
start_index
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
View(output_dataframe)
parsed_course_pages[[3]]
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
parsed_course_pages[[3]]
pages <- parsed_course_pages[[3]]
list_text <- pages %>% html_nodes("li") %>% html_text()
list_text
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
View(output_dataframe)
#purpose of script: scrape readme lists, extract & assign course type
extract_course_type(parsed_course_pages[[1]])
#purpose of script: scrape readme lists, extract & assign course type
extract_course_type(parsed_course_pages[[2]])
#purpose of script: scrape readme lists, extract & assign course type
extract_course_type(parsed_course_pages[[3]])
#purpose of script: scrape readme lists, extract & assign course type
extract_course_type(parsed_course_pages[[4]])
#purpose of script: scrape readme lists, extract & assign course type
extract_course_type(parsed_course_pages[[5]])
#purpose of script: scrape readme lists, extract & assign course type
extract_course_type(parsed_course_pages[[6]])
#purpose of script: scrape readme lists, extract & assign course type
extract_course_type(parsed_course_pages[[7]])
#purpose of script: scrape readme lists, extract & assign course type
extract_course_type(parsed_course_pages[[8]])
pages <- parsed_course_pages[[8]]
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start - find the first node containing e learning
#find first index
start_index <- grep("e learning", lowered_list_text)[length(grep("e learning", lowered_list_text))]
start_index
#find end index containing face to face
end_index <- grep("face to face", lowered_list_text)[length(grep("face to face", lowered_list_text))]
end_index
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
length(start_index) == 0 | length(end_index) == 0
extract_course_type <- function(pages){
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start - find the first node containing e learning
#find first index
start_index <- grep("e learning", lowered_list_text)[length(grep("e learning", lowered_list_text))]
#find end index containing face to face
end_index <- grep("face to face", lowered_list_text)[length(grep("face to face", lowered_list_text))]
#need to cover missing course types here
if (length(start_index) == 0 | length(end_index) == 0){
course_type <- "No course type detected"
next
}
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
#pull the last 3 elements for course type
course_type_test <- paste(tail(user_generated_li, 3), collapse = "; ")
#if any of these patterns are detected, assign the value to course type
if (grepl("E learning", course_type_test) |
grepl("Self learning", course_type_test) |
grepl("Face to face", course_type_test)
){
course_type <- course_type_test
} else {
#otherwise use placeholder text
course_type <- "No course type found"
}
return(course_type)
} #end of function
#apply the function to extract course descriptions from the parsed course list
course_type_list <- lapply(parsed_course_pages, FUN = extract_course_type)
#apply the function to extract course descriptions from the parsed course list
course_type_list <- lapply(parsed_course_pages, FUN = extract_course_type)
extract_course_type <- function(pages){
list_text <- pages %>% html_nodes("li") %>% html_text()
#lower for pattern matching
lowered_list_text <- list_text %>% tolower()
#subset this character vector by:
#start - find the first node containing e learning
#find first index
start_index <- grep("e learning", lowered_list_text)[length(grep("e learning", lowered_list_text))]
#find end index containing face to face
end_index <- grep("face to face", lowered_list_text)[length(grep("face to face", lowered_list_text))]
#need to cover missing course types here
if (length(start_index) == 0 | length(end_index) == 0){
course_type <- "No course type detected"
} else {
#subset the character vector by these indices
user_generated_li <- list_text[start_index:end_index]
#pull the last 3 elements for course type
course_type_test <- paste(tail(user_generated_li, 3), collapse = "; ")
#if any of these patterns are detected, assign the value to course type
if (grepl("E learning", course_type_test) |
grepl("Self learning", course_type_test) |
grepl("Face to face", course_type_test)
){
course_type <- course_type_test
} else {
#otherwise use placeholder text
course_type <- "No course type found"
}
}
return(course_type)
} #end of function
#apply the function to extract course descriptions from the parsed course list
course_type_list <- lapply(parsed_course_pages, FUN = extract_course_type)
course_type_list
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
print(output_dataframe$site_link[11])
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
lowered_output
# -------------------------------------------------------------------------
# -------------------------------------------------------------------------
# -------------------------------------------------------------------------
class(lowered_output)
lowered_output[11, ]
lowered_output[10, ]
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
parsed_course_pages[[11]]
pages <- parsed_course_pages[[11]]
#assign parsed page
paragraph_nodes <- pages %>% html_nodes("p") %>% html_text()
paragraph_nodes
parsed_course_pages[[11]]
pages <- parsed_course_pages[[12]]
#assign parsed page
paragraph_nodes <- pages %>% html_nodes("p") %>% html_text()
paragraph_nodes
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
print(output_dataframe$site_link[12])
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
source('~/dsca_course_catalogue_dev/src/initialise.R', echo=TRUE)
View(output_dataframe)
